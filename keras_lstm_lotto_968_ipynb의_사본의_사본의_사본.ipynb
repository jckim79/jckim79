{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "cell_execution_strategy": "setup",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jckim79/jckim79/blob/main/keras_lstm_lotto_968_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8%EC%9D%98_%EC%82%AC%EB%B3%B8%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzEHCTprsvry"
      },
      "source": [
        "# 딥러닝 로또 번호 예측\n",
        "\n",
        "- 딥러닝 로또 예측 번호 확인: https://animalface.site/lotto\n",
        "\n",
        "- 동영상 설명: 유튜브 조코딩 채널(https://www.youtube.com/channel/UCQNE2JmbasNYbjGAcuBiRRg)\n",
        "\n",
        "- 참고 문헌: 김태영님 블로그(https://tykimos.github.io/2020/01/25/keras_lstm_lotto_v895/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.10 -m venv my_env"
      ],
      "metadata": {
        "id": "eU7YsaKsMs-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source my_env/bin/activate"
      ],
      "metadata": {
        "id": "w72bZ4rZMswZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y python3.10"
      ],
      "metadata": {
        "id": "3iDobn-oRU2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !apt install python3.10-venv\n"
      ],
      "metadata": {
        "id": "EhDITq9pR_Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.10 -m venv tf210_env"
      ],
      "metadata": {
        "id": "EULX4Ei3Rv1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source tf210_env/bin/activate"
      ],
      "metadata": {
        "id": "3zPj45MgSL9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.10 -m venv tf210_env  # Create a new environment\n",
        "!source tf210_env/bin/activate  # Activate the environment"
      ],
      "metadata": {
        "id": "yRv-fQK9W5sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --platform manylinux2014_x86_64 --python-version 39 tensorflow_gpu==2.10.0 --only-binary=:all: --target=/tmp/tensorflow_gpu\n",
        "!pip install numpy pandas matplotlib # any other requirements"
      ],
      "metadata": {
        "id": "oGBTrNRFW6bC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import numpy as np\n",
        "\n",
        "# Handle potential empty strings, non-numeric characters, and quotes\n",
        "converters = {i: lambda s: float(s.strip().replace('\"', '') or 0) for i in range(7)}\n",
        "\n",
        "# Load the data, specifying to use only the first 7 columns (indices 0 to 6)\n",
        "# This avoids the error caused by inconsistent column counts in the file\n",
        "rows = np.loadtxt(\"./lotto.csv\", delimiter=\",\", converters=converters, encoding='utf-8-sig', usecols=range(7))\n",
        "row_count = len(rows)\n",
        "print(row_count)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "YXk9vgc54KCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAl4CkLsKU8w"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 당첨번호를 원핫인코딩벡터(ohbin)으로 변환\n",
        "def numbers2ohbin(numbers):\n",
        "\n",
        "    ohbin = np.zeros(45) #45개의 빈 칸을 만듬\n",
        "\n",
        "    for i in range(6): #여섯개의 당첨번호에 대해서 반복함\n",
        "        ohbin[int(numbers[i])-1] = 1 #로또번호가 1부터 시작하지만 벡터의 인덱스 시작은 0부터 시작하므로 1을 뺌\n",
        "\n",
        "    return ohbin\n",
        "\n",
        "# 원핫인코딩벡터(ohbin)를 번호로 변환\n",
        "def ohbin2numbers(ohbin):\n",
        "\n",
        "    numbers = []\n",
        "\n",
        "    for i in range(len(ohbin)):\n",
        "        if ohbin[i] == 1.0: # 1.0으로 설정되어 있으면 해당 번호를 반환값에 추가한다.\n",
        "            numbers.append(i+1)\n",
        "\n",
        "    return numbers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aty_CLiHFyFr"
      },
      "source": [
        "numbers = rows[:, 1:7]\n",
        "ohbins = list(map(numbers2ohbin, numbers))\n",
        "\n",
        "x_samples = ohbins[0:row_count-1]\n",
        "y_samples = ohbins[1:row_count]\n",
        "\n",
        "#원핫인코딩으로 표시\n",
        "print(\"ohbins\")\n",
        "print(\"X[0]: \" + str(x_samples[0]))\n",
        "print(\"Y[0]: \" + str(y_samples[0]))\n",
        "\n",
        "#번호로 표시\n",
        "print(\"numbers\")\n",
        "print(\"X[0]: \" + str(ohbin2numbers(x_samples[0])))\n",
        "print(\"Y[0]: \" + str(ohbin2numbers(y_samples[0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Eg9su7zHya9"
      },
      "source": [
        "train_idx = (0, 800)\n",
        "val_idx = (801,900)\n",
        "test_idx = (901, len(x_samples))\n",
        "\n",
        "print(\"train: {0}, val: {1}, test: {2}\".format(train_idx, val_idx, test_idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_sZgx_vnJI1v"
      }
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "# Define the input shape with batch size\n",
        "input_shape = (1, 1, 45)  # (batch_size, timesteps, features)\n",
        "\n",
        "# Define the input layer, using only batch_shape for stateful LSTM\n",
        "inputs = keras.Input(batch_shape=input_shape)\n",
        "\n",
        "# Define the LSTM layer\n",
        "lstm_layer = layers.LSTM(128, return_sequences=False, stateful=True)(inputs)\n",
        "\n",
        "# Define the output layer\n",
        "outputs = layers.Dense(45, activation='sigmoid')(lstm_layer)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "1zC02ZyHYrFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmml5sIBJ191"
      },
      "source": [
        "# 매 에포크마다 훈련과 검증의 손실 및 정확도를 기록하기 위한 변수\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "# 최대 100번 에포크까지 수행\n",
        "for epoch in range(100):\n",
        "\n",
        "    # Reset the state of the LSTM layer instead of the entire model\n",
        "    model.layers[1].reset_states()  # 중요! 매 에포크마다 1회부터 다시 훈련하므로 상태 초기화 필요\n",
        "\n",
        "    batch_train_loss = []\n",
        "    batch_train_acc = []\n",
        "\n",
        "    for i in range(train_idx[0], train_idx[1]):\n",
        "\n",
        "        xs = x_samples[i].reshape(1, 1, 45)\n",
        "        ys = y_samples[i].reshape(1, 45)\n",
        "\n",
        "        loss, acc = model.train_on_batch(xs, ys) #배치만큼 모델에 학습시킴\n",
        "\n",
        "        batch_train_loss.append(loss)\n",
        "        batch_train_acc.append(acc)\n",
        "\n",
        "    train_loss.append(np.mean(batch_train_loss))\n",
        "    train_acc.append(np.mean(batch_train_acc))\n",
        "\n",
        "    batch_val_loss = []\n",
        "    batch_val_acc = []\n",
        "\n",
        "    for i in range(val_idx[0], val_idx[1]):\n",
        "\n",
        "        xs = x_samples[i].reshape(1, 1, 45)\n",
        "        ys = y_samples[i].reshape(1, 45)\n",
        "\n",
        "        loss, acc = model.test_on_batch(xs, ys) #배치만큼 모델에 입력하여 나온 답을 정답과 비교함\n",
        "\n",
        "        batch_val_loss.append(loss)\n",
        "        batch_val_acc.append(acc)\n",
        "\n",
        "    val_loss.append(np.mean(batch_val_loss))\n",
        "    val_acc.append(np.mean(batch_val_acc))\n",
        "\n",
        "    print('epoch {0:4d} train acc {1:0.3f} loss {2:0.3f} val acc {3:0.3f} loss {4:0.3f}'.format(epoch, np.mean(batch_train_acc), np.mean(batch_train_loss), np.mean(batch_val_acc), np.mean(batch_val_loss)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Ensure the indices are within the bounds of x_samples\n",
        "total_samples = len(x_samples)\n",
        "train_idx = (0, 800)\n",
        "val_idx = (801, 900)\n",
        "\n",
        "# Adjust the validation and test indices if they exceed the total number of samples\n",
        "if val_idx[0] >= total_samples:\n",
        "    val_idx = (total_samples, total_samples) # Empty validation set\n",
        "if val_idx[1] > total_samples:\n",
        "    val_idx = (val_idx[0], total_samples)\n",
        "\n",
        "# Calculate the test index based on the end of the validation index and total samples\n",
        "test_idx = (val_idx[1], total_samples)\n",
        "\n",
        "print(\"train: {0}, val: {1}, test: {2}\".format(train_idx, val_idx, test_idx))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "0DYWh_734fGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBvBzBL0WoU1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "for data, color, label, ax in zip(\n",
        "    [train_loss, val_loss, train_acc, val_acc],\n",
        "    ['y', 'r', 'b', 'g'],\n",
        "    ['train loss', 'val loss', 'train acc', 'val acc'],\n",
        "    [ax1, ax1, ax2, ax2]\n",
        "):\n",
        "    ax.plot(data, color, label=label)\n",
        "\n",
        "ax1.set_xlabel('epoch')\n",
        "ax1.set_ylabel('loss')\n",
        "ax2.set_ylabel('accuracy')\n",
        "\n",
        "ax1.legend(loc='upper left')\n",
        "ax2.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRTu3x_ja-6y"
      },
      "source": [
        "# 88회부터 지금까지 1등부터 5등까지 상금의 평균낸다.\n",
        "mean_prize = [ np.mean(rows[87:, 8]),\n",
        "           np.mean(rows[87:, 9]),\n",
        "           np.mean(rows[87:, 10]),\n",
        "           np.mean(rows[87:, 11]),\n",
        "           np.mean(rows[87:, 12])]\n",
        "\n",
        "print(mean_prize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import numpy as np\n",
        "\n",
        "# Handle potential empty strings, non-numeric characters, and quotes\n",
        "# Extend converters to handle columns up to index 12\n",
        "converters = {i: lambda s: float(s.strip().replace('\"', '') or 0) for i in range(13)}\n",
        "\n",
        "# Load the data, specifying to use columns from index 0 to 12 (inclusive)\n",
        "# This includes the lottery numbers and the prize money columns\n",
        "rows = np.loadtxt(\"./lotto.csv\", delimiter=\",\", converters=converters, encoding='utf-8-sig', usecols=range(13))\n",
        "\n",
        "# Assuming columns 1 to 6 contain the lottery numbers\n",
        "lottery_number_columns = rows[:, 1:7]\n",
        "\n",
        "# Create a mask to identify rows where any number is outside the range [1, 45]\n",
        "# Ensure this check still works with potentially more columns loaded\n",
        "invalid_rows_mask = np.any((lottery_number_columns < 1) | (lottery_number_columns > 45), axis=1)\n",
        "\n",
        "# Filter out the invalid rows\n",
        "filtered_rows = rows[~invalid_rows_mask]\n",
        "\n",
        "# Update row_count and proceed with the filtered data\n",
        "row_count = len(filtered_rows)\n",
        "print(f\"Original row count: {len(rows)}\")\n",
        "print(f\"Filtered row count: {row_count}\")\n",
        "\n",
        "# Now use the filtered_rows for further processing\n",
        "# Update 'rows' to refer to the filtered data for consistency\n",
        "rows = filtered_rows\n",
        "\n",
        "numbers = rows[:, 1:7]\n",
        "\n",
        "# ... (rest of your code that uses the 'rows' variable should now work)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "To5bJCdGVSnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSHMYwMadiCG"
      },
      "source": [
        "# 등수와 상금을 반환함\n",
        "# 순위에 오르지 못한 경우에는 등수가 0으로 반환함\n",
        "def calc_reward(true_numbers, true_bonus, pred_numbers):\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for ps in pred_numbers:\n",
        "        if ps in true_numbers:\n",
        "            count += 1\n",
        "\n",
        "    if count == 6:\n",
        "        return 0, mean_prize[0]\n",
        "    elif count == 5 and true_bonus in pred_numbers:\n",
        "        return 1, mean_prize[1]\n",
        "    elif count == 5:\n",
        "        return 2, mean_prize[2]\n",
        "    elif count == 4:\n",
        "        return 3, mean_prize[3]\n",
        "    elif count == 3:\n",
        "        return 4, mean_prize[4]\n",
        "\n",
        "    return 5, 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_-HVUOaa3nJ"
      },
      "source": [
        "def gen_numbers_from_probability(nums_prob):\n",
        "\n",
        "    ball_box = []\n",
        "\n",
        "    for n in range(45):\n",
        "        ball_count = int(nums_prob[n] * 100 + 1)\n",
        "        ball = np.full((ball_count), n+1) #1부터 시작\n",
        "        ball_box += list(ball)\n",
        "\n",
        "    selected_balls = []\n",
        "\n",
        "    while True:\n",
        "\n",
        "        if len(selected_balls) == 6:\n",
        "            break\n",
        "\n",
        "        ball_index = np.random.randint(len(ball_box), size=1)[0]\n",
        "        ball = ball_box[ball_index]\n",
        "\n",
        "        if ball not in selected_balls:\n",
        "            selected_balls.append(ball)\n",
        "\n",
        "    return selected_balls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UefCTe2yRYy"
      },
      "source": [
        "train_total_reward = []\n",
        "train_total_grade = np.zeros(6, dtype=int)\n",
        "\n",
        "val_total_reward = []\n",
        "val_total_grade = np.zeros(6, dtype=int)\n",
        "\n",
        "test_total_reward = []\n",
        "test_total_grade = np.zeros(6, dtype=int)\n",
        "\n",
        "model.layers[1].reset_states()  # Assuming your LSTM layer is the second layer in the model (index 1)\n",
        "\n",
        "print('[No. ] 1st 2nd 3rd 4th 5th 6th Rewards')\n",
        "\n",
        "for i in range(len(x_samples)):\n",
        "    xs = x_samples[i].reshape(1, 1, 45)\n",
        "    ys_pred = model.predict_on_batch(xs) # 모델의 출력값을 얻음\n",
        "\n",
        "    sum_reward = 0\n",
        "    sum_grade = np.zeros(6, dtype=int) # 6등까지 변수\n",
        "\n",
        "    for n in range(10): # 10판 수행\n",
        "        numbers = gen_numbers_from_probability(ys_pred[0])\n",
        "\n",
        "        #i회차 입력 후 나온 출력을 i+1회차와 비교함\n",
        "        grade, reward = calc_reward(rows[i+1,1:7], rows[i+1,7], numbers)\n",
        "\n",
        "        sum_reward += reward\n",
        "        sum_grade[grade] += 1\n",
        "\n",
        "        if i >= train_idx[0] and i < train_idx[1]:\n",
        "            train_total_grade[grade] += 1\n",
        "        elif i >= val_idx[0] and i < val_idx[1]:\n",
        "            val_total_grade[grade] += 1\n",
        "        elif i >= test_idx[0] and i < test_idx[1]:\n",
        "            val_total_grade[grade] += 1\n",
        "\n",
        "    if i >= train_idx[0] and i < train_idx[1]:\n",
        "        train_total_reward.append(sum_reward)\n",
        "    elif i >= val_idx[0] and i < val_idx[1]:\n",
        "        val_total_reward.append(sum_reward)\n",
        "    elif i >= test_idx[0] and i < test_idx[1]:\n",
        "        test_total_reward.append(sum_reward)\n",
        "\n",
        "    print('[{0:4d}] {1:3d} {2:3d} {3:3d} {4:3d} {5:3d} {6:3d} {7:15,d}'.format(i+1, sum_grade[0], sum_grade[1], sum_grade[2], sum_grade[3], sum_grade[4], sum_grade[5], int(sum_reward)))\n",
        "\n",
        "print('Total')\n",
        "print('==========')\n",
        "print('Train {0:5d} {1:5d} {2:5d} {3:5d} {4:5d} {5:5d} {6:15,d}'.format(train_total_grade[0], train_total_grade[1], train_total_grade[2], train_total_grade[3], train_total_grade[4], train_total_grade[5], int(sum(train_total_reward))))\n",
        "print('Val   {0:5d} {1:5d} {2:5d} {3:5d} {4:5d} {5:5d} {6:15,d}'.format(val_total_grade[0], val_total_grade[1], val_total_grade[2], val_total_grade[3], val_total_grade[4], val_total_grade[5], int(sum(val_total_reward))))\n",
        "print('Test  {0:5d} {1:5d} {2:5d} {3:5d} {4:5d} {5:5d} {6:15,d}'.format(test_total_grade[0], test_total_grade[1], test_total_grade[2], test_total_grade[3], test_total_grade[4], test_total_grade[5], int(sum(test_total_reward))))\n",
        "print('==========')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig7ap8jnfZUL"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "total_reward = train_total_reward + val_total_reward + test_total_reward\n",
        "\n",
        "plt.plot(total_reward)\n",
        "plt.ylabel('rewards')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "train_total_reward = []\n",
        "train_total_grade = np.zeros(6, dtype=int)\n",
        "\n",
        "val_total_reward = []\n",
        "val_total_grade = np.zeros(6, dtype=int)\n",
        "\n",
        "test_total_reward = []\n",
        "test_total_grade = np.zeros(6, dtype=int)\n",
        "\n",
        "# 88회부터 지금까지 1등부터 5등까지 상금의 평균을 계산합니다.\n",
        "# 이 코드를 calc_reward 함수 호출 전에 배치하여 NameError를 방지합니다.\n",
        "mean_prize = [ np.mean(rows[87:, 8]),\n",
        "           np.mean(rows[87:, 9]),\n",
        "           np.mean(rows[87:, 10]),\n",
        "           np.mean(rows[87:, 11]),\n",
        "           np.mean(rows[87:, 12])]\n",
        "\n",
        "model.layers[1].reset_states()  # Assuming your LSTM layer is the second layer in the model (index 1)\n",
        "\n",
        "print('[No. ] 1st 2nd 3rd 4th 5th 6th Rewards')\n",
        "\n",
        "# len(x_samples) 대신 len(rows) - 1 을 사용합니다.\n",
        "# x_samples는 y_samples보다 하나 적으므로, rows[i+1] 접근 시 인덱스 오류가 발생할 수 있습니다.\n",
        "# calc_reward는 i+1 회차의 실제 번호와 비교하므로, 루프는 len(rows) - 1까지 실행되어야 합니다.\n",
        "for i in range(len(rows) - 1):\n",
        "    xs = x_samples[i].reshape(1, 1, 45)\n",
        "    ys_pred = model.predict_on_batch(xs) # 모델의 출력값을 얻음\n",
        "\n",
        "    sum_reward = 0\n",
        "    sum_grade = np.zeros(6, dtype=int) # 6등까지 변수\n",
        "\n",
        "    for n in range(10): # 10판 수행\n",
        "        numbers = gen_numbers_from_probability(ys_pred[0])\n",
        "\n",
        "        #i회차 입력 후 나온 출력을 i+1회차와 비교함\n",
        "        grade, reward = calc_reward(rows[i+1,1:7], rows[i+1,7], numbers)\n",
        "\n",
        "        sum_reward += reward\n",
        "        sum_grade[grade] += 1\n",
        "\n",
        "        # 인덱스 범위를 조정하여 i+1 회차와 비교한 결과를 저장합니다.\n",
        "        # i는 0부터 시작하지만, 결과는 i+1 회차에 대한 예측이므로 i+1을 사용합니다.\n",
        "        if (i+1) >= train_idx[0] and (i+1) < train_idx[1]:\n",
        "            train_total_grade[grade] += 1\n",
        "        elif (i+1) >= val_idx[0] and (i+1) < val_idx[1]:\n",
        "            val_total_grade[grade] += 1\n",
        "        elif (i+1) >= test_idx[0] and (i+1) < test_idx[1]:\n",
        "            test_total_grade[grade] += 1\n",
        "\n",
        "    # 인덱스 범위를 조정하여 i+1 회차와 비교한 결과를 저장합니다.\n",
        "    if (i+1) >= train_idx[0] and (i+1) < train_idx[1]:\n",
        "        train_total_reward.append(sum_reward)\n",
        "    elif (i+1) >= val_idx[0] and (i+1) < val_idx[1]:\n",
        "        val_total_reward.append(sum_reward)\n",
        "    elif (i+1) >= test_idx[0] and (i+1) < test_idx[1]:\n",
        "        test_total_reward.append(sum_reward)\n",
        "\n",
        "    print('[{0:4d}] {1:3d} {2:3d} {3:3d} {4:3d} {5:3d} {6:3d} {7:15,d}'.format(i+1, sum_grade[0], sum_grade[1], sum_grade[2], sum_grade[3], sum_grade[4], sum_grade[5], int(sum_reward)))\n",
        "\n",
        "\n",
        "print('Total')\n",
        "print('==========')\n",
        "print('Train {0:5d} {1:5d} {2:5d} {3:5d} {4:5d} {5:5d} {6:15,d}'.format(train_total_grade[0], train_total_grade[1], train_total_grade[2], train_total_grade[3], train_total_grade[4], train_total_grade[5], int(sum(train_total_reward))))\n",
        "print('Val   {0:5d} {1:5d} {2:5d} {3:5d} {4:5d} {5:5d} {6:15,d}'.format(val_total_grade[0], val_total_grade[1], val_total_grade[2], val_total_grade[3], val_total_grade[4], val_total_grade[5], int(sum(val_total_reward))))\n",
        "# Test 데이터 인덱스 저장 로직 수정:\n",
        "# test_total_grade와 test_total_reward에 결과가 저장되도록 수정합니다.\n",
        "print('Test  {0:5d} {1:5d} {2:5d} {3:5d} {4:5d} {5:5d} {6:15,d}'.format(test_total_grade[0], test_total_grade[1], test_total_grade[2], test_total_grade[3], test_total_grade[4], test_total_grade[5], int(sum(test_total_reward))))\n",
        "print('==========')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "jEdYrjL2Vpps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeM53wHLRmmA"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "ax = plt.figure().gca()\n",
        "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "\n",
        "rewards = [sum(train_total_reward), sum(val_total_reward), sum(test_total_reward)]\n",
        "\n",
        "class_color=['green', 'blue', 'red']\n",
        "\n",
        "plt.bar(['train', 'val', 'test'], rewards, color=class_color)\n",
        "plt.ylabel('rewards')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ... (previous code for data loading, preprocessing, etc.) ...\n",
        "\n",
        "# Define the input shape with batch size\n",
        "input_shape = (1, 1, 45)  # (batch_size, timesteps, features)\n",
        "\n",
        "# Define the input layer, using only batch_shape for stateful LSTM\n",
        "inputs = keras.Input(batch_shape=input_shape)\n",
        "\n",
        "# Define the LSTM layer\n",
        "lstm_layer = layers.LSTM(128, return_sequences=False, stateful=True)(inputs)\n",
        "\n",
        "# Define the output layer\n",
        "outputs = layers.Dense(45, activation='sigmoid')(lstm_layer)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# ... (previous code for calc_reward, gen_numbers_from_probability) ...\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Variables for tracking training and validation metrics\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "# Maximum number of epochs\n",
        "max_epochs = 100\n",
        "\n",
        "# Training loop with early stopping\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "    # Reset the state of the LSTM layer\n",
        "    model.layers[1].reset_states()\n",
        "\n",
        "    batch_train_loss = []\n",
        "    batch_train_acc = []\n",
        "\n",
        "    for i in range(train_idx[0], train_idx[1]):\n",
        "        xs = x_samples[i].reshape(1, 1, 45)\n",
        "        ys = y_samples[i].reshape(1, 45)\n",
        "        loss, acc = model.train_on_batch(xs, ys)\n",
        "        batch_train_loss.append(loss)\n",
        "        batch_train_acc.append(acc)\n",
        "\n",
        "    train_loss.append(np.mean(batch_train_loss))\n",
        "    train_acc.append(np.mean(batch_train_acc))\n",
        "\n",
        "    batch_val_loss = []\n",
        "    batch_val_acc = []\n",
        "\n",
        "    for i in range(val_idx[0], val_idx[1]):\n",
        "        xs = x_samples[i].reshape(1, 1, 45)\n",
        "        ys = y_samples[i].reshape(1, 45)\n",
        "        loss, acc = model.test_on_batch(xs, ys)\n",
        "        batch_val_loss.append(loss)\n",
        "        batch_val_acc.append(acc)\n",
        "\n",
        "    val_loss.append(np.mean(batch_val_loss))\n",
        "    val_acc.append(np.mean(batch_val_acc))\n",
        "\n",
        "    print('epoch {0:4d} train acc {1:0.3f} loss {2:0.3f} val acc {3:0.3f} loss {4:0.3f}'.format(epoch, np.mean(batch_train_acc), np.mean(batch_train_loss), np.mean(batch_val_acc), np.mean(batch_val_loss)))\n",
        "\n",
        "    # Check for early stopping\n",
        "    if len(val_loss) > 10 and val_loss[-1] > val_loss[-11]:  # Stop if val_loss hasn't improved in 10 epochs\n",
        "        print(\"Early stopping triggered at epoch\", epoch)\n",
        "        break\n",
        "\n",
        "# Get optimal epoch\n",
        "optimal_epoch = len(val_loss) - 10\n",
        "\n",
        "# Print optimal epoch\n",
        "print(\"Optimal epoch:\", optimal_epoch)\n",
        "\n",
        "# Get probabilities for each number\n",
        "xs = x_samples[-1].reshape(1, 1, 45)  # Use the last input sequence for prediction\n",
        "ys_pred = model.predict_on_batch(xs)\n",
        "probabilities = ys_pred[0]  # Probabilities for each number (0-44)\n",
        "\n",
        "# Print probabilities\n",
        "print(\"Probabilities for each number (1-45):\")\n",
        "for i, prob in enumerate(probabilities):\n",
        "    print(f\"{i + 1}: {prob:.4f}\")"
      ],
      "metadata": {
        "id": "D4VqFMwpiIU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azY1xvegfCMG"
      },
      "source": [
        "# 마지막 회차까지 학습한 모델로 다음 회차 추론\n",
        "\n",
        "print('receive numbers')\n",
        "\n",
        "xs = x_samples[-1].reshape(1, 1, 45)\n",
        "\n",
        "ys_pred = model.predict_on_batch(xs)\n",
        "\n",
        "list_numbers = []\n",
        "\n",
        "for n in range(10):\n",
        "    numbers = gen_numbers_from_probability(ys_pred[0])\n",
        "    numbers.sort()\n",
        "    print('{0} : {1}'.format(n, numbers))\n",
        "    list_numbers.append(numbers)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}